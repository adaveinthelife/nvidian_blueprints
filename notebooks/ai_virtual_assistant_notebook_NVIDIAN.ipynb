{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78dc1a9c-d009-407e-836d-84cf85936ade",
   "metadata": {
    "id": "78dc1a9c-d009-407e-836d-84cf85936ade"
   },
   "source": [
    "# AI Virtual Assistant for Customer Service\n",
    "\n",
    "## Content\n",
    "\n",
    "* [Overview](#Overview)\n",
    "* [Software Components](#Software-components)\n",
    "* [Key Functionality](#Key-functionality)\n",
    "* [How it Works](#How-it-works)\n",
    "* [Key Components](#Key-Components)\n",
    "* [Prerequisites](#Prerequisites)\n",
    "* [Deployment - hands on starts here](#Deployment)\n",
    "* [Getting API Keys](#Getting-API-keys)\n",
    "* [Docker Compose Check](#Docker-compose-check)\n",
    "* [Clone the Repository & Set Up Environment](#Clone-the-Repository-&-Set-Up-Environment)\n",
    "* [Build the Docker Containers](#Build-the-Docker-containers)\n",
    "* [Ingest Data](#Ingest-Data)\n",
    "* [Exposing the Interface for Testing](#Exposing-the-Interface-for-Testing)\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "This Blueprint is showcasing an AI virtual assistant with NVIDIA NIM microservices (https://build.nvidia.com/nim)\n",
    "\n",
    "This blueprint is a reference solution for a text based virtual assistant. Companies are eager to enhance their customer service operations by integrating knowledge bases into AI assistants. Traditional approaches often fall short in delivering a combination of context-aware, secure, and real-time responses to complex customer queries. This results in longer resolution times, limited customer satisfaction, and potential data exposure risks. A centralized knowledge base that integrates seamlessly with internal applications and call center tools is vital to improving customer experience while ensuring data governance. The AI virtual assistant for customer service NVIDIA AI Blueprint, powered by NVIDIA NeMo Retriever™ and NVIDIA NIM™ microservices, along with retrieval-augmented generation (RAG), offers a streamlined solution for enhancing customer support. It implements context-aware, multi-turn conversations that feature general and personalized Q&A responses based on structured and unstructured data, such as order history and product details.\n",
    "\n",
    "This notebook will provide you with insights to the key components and walk you through its deployment and architecture in a step-by-step fashion. Note that this walk through is specific for the Docker Compose deployment. If you visit the [code repository](https://github.com/NVIDIA-AI-Blueprints/ai-virtual-assistant), you will find additional information and other forms of deployment instructions (e.g. Helm chart deployment).\n",
    "\n",
    "## Software Components\n",
    "\n",
    "- NVIDIA NIM microservices\n",
    "    - Response Generation (Inference)\n",
    "        - NIM of meta/llama-3.1-70b-instruct\n",
    "        - NIM of nvidia/nv-embedqa-e5-v5\n",
    "        - NIM of nvidia/rerank-qa-mistral-4b\n",
    "    - Synthetic Data Generation for reference\n",
    "        - NIM of Nemotron4-340B\n",
    "- Orchestrator Agent - LangGraph based\n",
    "- Text Retrievers - LangChain\n",
    "- Structured Data (CSV) Ingestion - Postgres Database\n",
    "- Unstructured Data (PDF) Ingestion - Milvus Database (Vector GPU-optimized)\n",
    "\n",
    "Docker Compose scripts are provided which spin up the microservices on a single node. When ready for a larger-scale deployment, you can use the included Helm charts to spin up the necessary microservices. You will use sample Jupyter notebooks with the JupyterLab service to interact with the code directly.\n",
    "\n",
    "The Blueprint contains sample use-case data pertaining to retail product catalog and customer data with purchase history but Developers can build upon this blueprint, by customizing the RAG application to their specific use case. A sample customer service agent user interface and API-based analytic server for conversation summary and sentiment are also included.\n",
    "\n",
    "## Key Functionality\n",
    "\n",
    "- Personalized Responses: Handles structured and unstructured customer queries (e.g., order details, spending history).\n",
    "- Multi-Turn Dialogue: Offers context-aware, seamless interactions across multiple questions.\n",
    "- Custom Conversation Style: Adapts text responses to reflect corporate branding and tone.\n",
    "- Sentiment Analysis: Analyzes real-time customer interactions to gauge sentiment and adjust responses.\n",
    "- Multi-Session Support: Allows for multiple user sessions with conversation history and summaries.\n",
    "- Data Privacy: Integrates with on-premises or cloud-hosted knowledge bases to protect sensitive data.\n",
    "\n",
    "By integrating NVIDIA NIM and RAG, the system empowers developers to build customer support solutions that can provide faster and more accurate support while maintaining data privacy.\n",
    "\n",
    "## How it works\n",
    "\n",
    "This blueprint uses a combination of retrieval-augmented generation and large language models to deliver an intelligent, context-aware virtual assistant for customer service. It connects to both structured data (like customer profiles and order histories) and unstructured data (like product manuals, FAQs) so that it can find and present relevant information in real time.\n",
    "\n",
    "The process works as follows:\n",
    "\n",
    "- User Query: The customer asks a question in natural language.\n",
    "- Data Retrieval: The system retrieves relevant data—such as support documents or order details—by embedding and searching through internal databases, product manuals, and FAQs.\n",
    "- Contextual Reasoning: A large language model uses these retrieved details to generate a helpful, coherent, and contextually appropriate response.\n",
    "- Additional Capabilities: Tools like sentiment analysis gauge the user’s satisfaction and conversation summaries help supervisors quickly review interactions.\n",
    "- Continuous Improvement: Feedback from interactions is fed back into the system, refining the model’s accuracy and efficiency over time. The end result is a virtual assistant that can understand complex questions, find the right information, and provide personalized, human-like responses.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "The detailed architecture consists of the following components:\n",
    "\n",
    "**Sample Data** The blueprint comes with synthetic sample data representing a typical customer service function, including customer profiles, order histories (structured data), and technical product manuals (unstructured data). A notebook is provided to guide users on how to ingest both structured and unstructured data efficiently.\n",
    "\n",
    "Structured Data: Includes customer profiles and order history Unstructured Data: Ingests product manuals, product catalogs, and FAQs\n",
    "\n",
    "**AI Agent** This reference solution implements three sub-agents using the open-source LangGraph framework. These sub-agents address common customer service tasks for the included sample dataset. They rely on the Llama 3.1 model 70B and NVIDIA NIM microservices for generating responses, converting natural language into SQL queries, and assessing the sentiment of the conversation.\n",
    "\n",
    "**Structured Data Retriever** Works in tandem with a Postgres database and Vanna.AI to fetch relevant data based on user queries.\n",
    "\n",
    "**Unstructured Data Retriever** Processes unstructured data (e.g., PDFs, FAQs) by chunking it, creating embeddings using the NeMo Retriever embedding NIM, and storing it in Milvus for fast retrieval.\n",
    "\n",
    "**Analytics and Admin Operations** To support operational requirements, the blueprint includes reference code for managing key administrative tasks:\n",
    "\n",
    "- Storing conversation histories\n",
    "- Generating conversation summaries\n",
    "- Conducting sentiment analysis on customer interactions These features ensure that customer service teams can efficiently monitor and evaluate interactions for quality and performance.\n",
    "\n",
    "**Data Flywheel** The blueprint includes a robust set of APIs, some of which are explicitly designed for feedback collection (identified by 'feedback' in their URLs). These APIs support the process of gathering data for continuous model improvement, forming a feedback loop or 'data flywheel.' While this process enables refinement of the model's performance over time to improve accuracy and cost-effectiveness, it is important to note that they do not directly perform the model fine-tuning itself.\n",
    "\n",
    "**Summary** In summary, this NVIDIA AI Blueprint offers a comprehensive solution for building intelligent, generative AI-powered virtual assistants for customer service, leveraging structured and unstructured data to deliver personalized and efficient support. It includes all necessary tools and guidance to deploy, monitor, and continually improve the solution in real-world environments.\n",
    "\n",
    "![Blueprint Diagram](https://github.com/NVIDIA-AI-Blueprints/ai-virtual-assistant/raw/main/docs/imgs/IVA-blueprint-diagram-r5.png)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "### Docker compose\n",
    "\n",
    "#### System requirements\n",
    "\n",
    "Ubuntu 20.04 or 22.04 based machine, with sudo privileges\n",
    "\n",
    "Install software requirements\n",
    "- Install Docker Engine and Docker Compose. Refer to the instructions for Ubuntu.\n",
    "- Ensure the Docker Compose plugin version is 2.29.1 or higher.\n",
    "- Run docker compose version to confirm.\n",
    "- Refer to Install the Compose plugin in the Docker documentation for more information.\n",
    "- To configure Docker for GPU-accelerated containers, install the NVIDIA Container Toolkit.\n",
    "- Install git\n",
    "\n",
    "By default the provided configurations use GPU optimized databases such as Milvus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35890619-980d-4176-bbcb-c696a411d83f",
   "metadata": {
    "id": "35890619-980d-4176-bbcb-c696a411d83f"
   },
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf74f11-ef47-44b5-8f75-fc9e2a6fcf55",
   "metadata": {},
   "source": [
    "## Install required modules\n",
    "\n",
    "Restart the kernel after running following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52809252-4116-48dd-affd-5567f3e35e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7b9159-d45b-4f4b-99f8-d857c360dd86",
   "metadata": {},
   "source": [
    "## Apply for an NVIDIA NGC Account\n",
    "To use the NVIDIA AI Foundational Models, you will need to apply for an account on [NVIDIA NGC](https://ngc.nvidia.com). Nvidia GPU cloud (NGC) is a GPU-accelerated cloud platform portal optimized for deep learning and scientific computing.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Steps\n",
    "1. Go to the [NVIDIA NGC page](https://ngc.nvidia.com)\n",
    "2. If not logged in, click the \"Welcome Guest\" icon in the top right corner of the page and select \"Sign In / Sign Up\"\n",
    "3. Login with your NVIDIA email\n",
    "4. Select NV-Developer as your NVIDIA Cloud Account and agree to the terms & conditions\n",
    "5. Click on the profile icon at the top-right and select Setup\n",
    "6. Click Generate Personal Key.\n",
    "7. In the popup window that appears:\n",
    "  * Enter a name for your personal key\n",
    "  * Select a expiration date of 12 months\n",
    "  * Select \"Cloud Functions\" under the \"Services Included\" field\n",
    "8. Copy and save this API key. __IMPORTANT__ Keep this somewhere safe because it will only display it once! If you lose your key, you'll have to create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044596c7-801c-4bfa-b9f6-e940cab81993",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "044596c7-801c-4bfa-b9f6-e940cab81993",
    "outputId": "8f4c4700-9cc2-47f4-e122-3b1ae38b8ab3"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "def set_ngc_api_key():\n",
    "    \"\"\"Prompt for and set the NVIDIA API key if not already valid.\"\"\"\n",
    "    while True:\n",
    "        key = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
    "        if key.startswith(\"nvapi-\"):\n",
    "            break\n",
    "        print(\"Invalid API key. Please try again.\")\n",
    "\n",
    "    return key\n",
    "\n",
    "# Check if the key is already set and valid\n",
    "NVIDIA_API_KEY = os.environ.get(\"NVIDIA_API_KEY\", \"\")\n",
    "\n",
    "if not NVIDIA_API_KEY.startswith(\"nvapi-\"):\n",
    "    print(\"NVIDIA API Key is missing or invalid.\")\n",
    "    NVIDIA_API_KEY = set_ngc_api_key()\n",
    "else:\n",
    "    print(\"NVIDIA API Key is already set.\")\n",
    "    if input(\"Would you like to enter a different key? (yes/no): \").strip().lower() in [\"yes\", \"y\"]:\n",
    "        NVIDIA_API_KEY = set_ngc_api_key()\n",
    "\n",
    "# Set all related environment variables\n",
    "for var in [\"NVIDIA_API_KEY\", \"NGC_CLI_API_KEY\", \"NGC_API_KEY\"]:\n",
    "    os.environ[var] = NVIDIA_API_KEY\n",
    "\n",
    "print(\"API keys configured successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7L1yGbPtGF4q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "id": "7L1yGbPtGF4q",
    "outputId": "c11b4632-d2c2-44ba-b373-a9d767a317cd"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = f\"{NVIDIA_API_KEY}\"\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"nvdev/meta/llama-3.3-70b-instruct\",\n",
    "  messages=[{\"role\":\"user\",\"content\":\"Write a limerick about the wonders of GPU computing.\"}],\n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "  if chunk.choices[0].delta.content is not None:\n",
    "    print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba880dd",
   "metadata": {
    "id": "fba880dd"
   },
   "source": [
    "## Docker Compose check\n",
    "Ensure the Docker Compose plugin version is 2.29.1 or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b222afe-67e0-4a7d-b450-dff89e9bc22b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7b222afe-67e0-4a7d-b450-dff89e9bc22b",
    "outputId": "017c4b6a-f1bf-44e0-aac4-82e49d3f1d85"
   },
   "outputs": [],
   "source": [
    "# Check certain versions and packages installed\n",
    "!docker compose version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d29236d",
   "metadata": {
    "id": "3d29236d"
   },
   "source": [
    "## Clone the Repository & Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe83be0d-7c6a-493d-aa85-ac2e2cd168ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe83be0d-7c6a-493d-aa85-ac2e2cd168ae",
    "outputId": "88cd1b34-d3c8-48f2-9b34-1c52ec95594f"
   },
   "outputs": [],
   "source": [
    "#  Clone the Repository\n",
    "!git clone https://github.com/NVIDIA-AI-Blueprints/ai-virtual-assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26290dfc",
   "metadata": {
    "id": "26290dfc"
   },
   "source": [
    "The purpose of this code snippet below is to ensure that the notebook is operating within a directory named \"ai-virtual-assistant\". If it's not, it changes to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f400b89-f9ca-41b4-95f0-eb771c88c617",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "4f400b89-f9ca-41b4-95f0-eb771c88c617",
    "outputId": "2a8b0af1-e666-44dc-c1d3-a8440ae825c2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_path = os.getcwd()\n",
    "last_part = os.path.basename(current_path)\n",
    "\n",
    "if os.path.basename(os.getcwd()) != \"ai-virtual-assistant\":\n",
    "    os.chdir(\"ai-virtual-assistant\")\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e1eeec",
   "metadata": {
    "id": "02e1eeec"
   },
   "source": [
    "We login into the NGC catalogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded8d982",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "ded8d982",
    "outputId": "14a0124b-1ae5-4136-b4f6-8d0ddb7b9843"
   },
   "outputs": [],
   "source": [
    "!docker login nvcr.io -u '$oauthtoken' -p $NGC_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed68679-155a-4ae9-befb-7cc94e111592",
   "metadata": {},
   "source": [
    "Let's update our `docker-compose.yaml` to use our [internal NVIDIA inference endpoints](https://nvidia.sharepoint.com/sites/nvbuild/SitePages/Endpoints-for-Internal-Development-Use.aspx).\n",
    "\n",
    "NVDev internal endpoints are replicas of the public API endpoints on build.nvidia.com and adhere to the exact same OpenAPI specification and maintain compatibility with all the same libraries and interfaces.\n",
    "\n",
    "To save time, we'll download a preconfigured version directly from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4ba5d-7c64-4f79-a974-5a36f8f9b4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download modified Docker compose from GitHub\n",
    "!wget -O ./deploy/compose/docker-compose.yaml https://raw.githubusercontent.com/adaveinthelife/nvidian_blueprints/main/docker_compose_files/ai_virtual_assistant/docker_compose.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd03972",
   "metadata": {
    "id": "cdd03972"
   },
   "source": [
    "## Build the Docker containers\n",
    "\n",
    "We are launching the containers by using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7387b26",
   "metadata": {
    "id": "a7387b26"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "compose_file = \"deploy/compose/docker-compose.yaml\"\n",
    "cmd = [\"docker\", \"compose\", \"-f\", compose_file, \"up\", \"-d\"]\n",
    "\n",
    "print(\"🚀 Starting containers...\")\n",
    "\n",
    "process = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "if process.returncode == 0:\n",
    "    print(\"✅ Docker containers started successfully.\")\n",
    "else:\n",
    "    print(\"❌ Failed to start containers.\")\n",
    "    print(\"stderr:\\n\", process.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618cbbc-4e6c-44db-85d0-b5dbe4617f33",
   "metadata": {
    "id": "b618cbbc-4e6c-44db-85d0-b5dbe4617f33"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "## Ensure the containers are spun up and look healthy\n",
    "docker ps --format \"table {{.ID}}\\t{{.Names}}\\t{{.Status}}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd0234b",
   "metadata": {
    "id": "0dd0234b"
   },
   "source": [
    "## Download data\n",
    "\n",
    "Download the manuals into data/manuals_pdf folder Run this script to download the manuals listed in the specified txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28623b0-d7c9-4502-9f38-0a41e0f4ba35",
   "metadata": {
    "id": "d28623b0-d7c9-4502-9f38-0a41e0f4ba35"
   },
   "outputs": [],
   "source": [
    "!./data/download.sh ./data/list_manuals.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a935841d-e2ba-4509-bc33-c24d26b31f83",
   "metadata": {},
   "source": [
    "## Ingest data\n",
    "\n",
    "Now it’s time to ingest our data. We'll use the Unstructured Data Ingestion APIs to extract, process, and prepare content the data we downloaded above. First, let’s set the ports for our Unstructured service and our localhost..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671f3be1-dc07-4b9a-a7aa-6dfab1527b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPADDRESS = \"172.17.0.1\"\n",
    "UNSTRUCTURED_DATA_PORT = \"9093\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf93d7-4e42-486f-a675-a508331faffe",
   "metadata": {},
   "source": [
    "### PDF Document Ingestion\n",
    "\n",
    "Before ingesting PDF documents, we’ll verify that the Unstructured Data Ingestion service is up and running by sending a health check request to its `/health` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1f4a7a-ac42-470e-ad2a-b8c279286ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = f'http://{IPADDRESS}:{UNSTRUCTURED_DATA_PORT}/health'\n",
    "print(url)\n",
    "headers = {\n",
    "    'accept': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Print the response\n",
    "print(response.status_code)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb23f2d-eb65-42eb-892b-a627ca48d104",
   "metadata": {},
   "source": [
    "#### Ingest PDFs\n",
    "\n",
    "In this step, we’ll upload all the downloaded PDF manuals from the `manuals_pdf directory`, along with any additional individual PDFs (like FAQ.pdf), to the Unstructured Data Ingestion API. Each file is sent via a POST request to the `/documents` endpoint, where it’s processed and prepared for downstream use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b50cdd5-14bb-4211-8b14-66df7859298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Base URL of the API endpoint\n",
    "url = f'http://{IPADDRESS}:{UNSTRUCTURED_DATA_PORT}/documents'\n",
    "\n",
    "# List of PDF file paths to upload (includes directory and individual files)\n",
    "pdf_files = []\n",
    "\n",
    "# Add all PDFs from the manuals directory\n",
    "manuals_dir = './data/manuals_pdf'\n",
    "pdf_files.extend([\n",
    "    os.path.join(manuals_dir, f)\n",
    "    for f in os.listdir(manuals_dir)\n",
    "    if f.endswith('.pdf')\n",
    "])\n",
    "\n",
    "# Add specific individual files\n",
    "pdf_files.append('./data/FAQ.pdf')\n",
    "\n",
    "# Upload each PDF\n",
    "for file_path in pdf_files:\n",
    "    with open(file_path, 'rb') as file:\n",
    "        files = {'file': file}\n",
    "        response = requests.post(url, files=files)\n",
    "    \n",
    "    # Print the response from the server\n",
    "    print(f'Uploaded {file_path}: {response.status_code}')\n",
    "    print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8610bcac-b4ed-4c20-8c87-b81162babf9b",
   "metadata": {},
   "source": [
    "#### Retrieve Uploaded Document List\n",
    "To verify which PDFs have been successfully uploaded, we send a GET request to the `/documents` endpoint. If the request is successful, the response will include a list of available documents, which is then formatted and displayed for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bfe38e-448b-418c-8790-042d52e1aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# URL of the API endpoint\n",
    "url = f'http://{IPADDRESS}:{UNSTRUCTURED_DATA_PORT}/documents'\n",
    "\n",
    "# Send the GET request\n",
    "response = requests.get(url)\n",
    "\n",
    "# Print the response from the server\n",
    "print(f'Response Status Code: {response.status_code}')\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    documents = data.get('documents', [])\n",
    "\n",
    "    # Format and print the list of documents\n",
    "    print(\"Available Documents:\")\n",
    "    for idx, document in enumerate(documents, start=1):\n",
    "        print(f\"{idx}. {document}\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve documents. Status Code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78b13a-b975-45a5-8b64-aa3e6e373c1d",
   "metadata": {},
   "source": [
    "### CSV Document Ingestion\n",
    "The Unstructured Data Ingestion API supports `.txt` files, but not CSVs directly. To work around this, we’ll first load the CSV data and then convert each row into a separate `.txt` file for ingestion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435be7af-d69a-4329-b168-e9137c0cd25e",
   "metadata": {},
   "source": [
    "#### Displaying the CSV data\n",
    "We’ll begin by loading the `gear-store.csv` file into a DataFrame and displaying the first few rows to get a quick look at the structure. We’ll also print the total number of entries to understand the dataset size before converting it for ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8e555-84a1-479a-a704-1dc3b9a32154",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "! pip install pandas\n",
    "! pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8b422e-e2ee-424f-a03b-4ab424f5209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Read and display the CSV data\n",
    "df = pd.read_csv('./data/gear-store.csv')\n",
    "display(df.head())\n",
    "\n",
    "# Show total number of rows\n",
    "print(f\"Total rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac4b03c-cef6-4316-8565-9b6ac00fa979",
   "metadata": {},
   "source": [
    "#### Converting and Ingesting CSV Data\n",
    "Now that we've reviewed the CSV content, we'll convert each row of the product DataFrame into a `.txt` file containing the item’s name, category, price, and description. Filenames are cleaned and formatted for consistency, and all files are saved to `./data/product` for us to use in the next step in the processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81629de-8bfe-4712-a3c9-5786d5ceb96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Function to create a valid filename\n",
    "def create_valid_filename(s):\n",
    "    # Remove invalid characters and replace spaces with underscores\n",
    "    s = re.sub(r'[^\\w\\-_\\. ]', '', s)\n",
    "    return s.replace(' ', '_')\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs('./data/product', exist_ok=True)\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Create filename using name, category, and subcategory\n",
    "    filename = f\"{create_valid_filename(row['name'])}_{create_valid_filename(row['category'])}_{create_valid_filename(row['subcategory'])}.txt\"\n",
    "\n",
    "    print(f\"Creating file {filename}, current index {index}\")\n",
    "    # Full path for the file\n",
    "    filepath = os.path.join('./data/product', filename)\n",
    "\n",
    "    # Create the content for the file\n",
    "    content = f\"Name: {row['name']}\\n\"\n",
    "    content += f\"Category: {row['category']}\\n\"\n",
    "    content += f\"Subcategory: {row['subcategory']}\\n\"\n",
    "    content += f\"Price: ${row['price']}\\n\"\n",
    "    content += f\"Description: {row['description']}\\n\"\n",
    "\n",
    "    # Write the content to the file\n",
    "    with open(filepath, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)\n",
    "\n",
    "print(f\"Created {len(df)} files in ./data/product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472657b2-699d-463a-a576-26c969a62a62",
   "metadata": {},
   "source": [
    "With the product text files prepared, this function uploads each file to the document ingestion API used by the virtual assistant. It includes a retry mechanism with exponential backoff to handle temporary issues like rate limits or server errors, ensuring reliable ingestion into the assistant’s retrieval system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6563f674-8436-4832-bb05-ebb947c4ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Retry configuration (Added due to rate limits for API Catalog embedding model )\n",
    "MAX_RETRIES = 5\n",
    "INITIAL_BACKOFF = 1  # Initial backoff in seconds\n",
    "\n",
    "def ingest_file(filepath: str) -> bool:\n",
    "    \"\"\"\n",
    "    Ingest file in canonical RAG retriever with retry mechanism\n",
    "\n",
    "    Args:\n",
    "        filepath: Path to the file to be ingested in retriever\n",
    "\n",
    "    Returns:\n",
    "        bool: Status of file ingestion\n",
    "    \"\"\"\n",
    "    # URL of the API endpoint\n",
    "    url = f'http://{IPADDRESS}:{UNSTRUCTURED_DATA_PORT}/documents'\n",
    "    retries = 0\n",
    "    backoff = INITIAL_BACKOFF\n",
    "\n",
    "    while retries <= MAX_RETRIES:\n",
    "        with open(filepath, 'rb') as file:\n",
    "            files = {'file': file}\n",
    "            try:\n",
    "                response = requests.post(url, files=files)\n",
    "\n",
    "                if response.status_code == 200:\n",
    "                    return True\n",
    "                elif response.status_code != 200:  # Handle Too Many Requests error\n",
    "                    if retries < MAX_RETRIES:\n",
    "                        print(f\"Internal Server error for {os.path.basename(filepath)}. Retrying after {backoff}s...\")\n",
    "                        time.sleep(backoff)\n",
    "                        backoff *= 2  # Exponential backoff\n",
    "                        retries += 1\n",
    "                    else:\n",
    "                        print(f\"Max retries reached for {os.path.basename(filepath)}. Giving up.\")\n",
    "                        return False\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Request failed for {os.path.basename(filepath)}: {e}\")\n",
    "                return False\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74544188-3b61-47d5-98fe-8e99e748a271",
   "metadata": {},
   "source": [
    "To speed up the ingestion process, this block uses multithreading to upload product files in parallel. Each file is submitted to the ingestion API using a thread pool, and results are tracked to report how many files were successfully ingested versus those that failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88124c6c-9f7d-4460-a747-0444b1b6c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "directory_path = './data/product'\n",
    "max_workers = 5  # Adjust this based on your system's capabilities and API limits\n",
    "\n",
    "filepaths = [os.path.join(directory_path, filename) for filename in os.listdir(directory_path) if filename.endswith(\".txt\")]\n",
    "filepaths\n",
    "\n",
    "successfully_ingested = []\n",
    "failed_ingestion = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    future_to_file = {executor.submit(ingest_file, filepath): filepath for filepath in filepaths}\n",
    "\n",
    "    for future in as_completed(future_to_file):\n",
    "        filepath = future_to_file[future]\n",
    "        try:\n",
    "            if future.result():\n",
    "                print(f\"Successfully Ingested {os.path.basename(filepath)}\")\n",
    "                successfully_ingested.append(filepath)\n",
    "            else:\n",
    "                print(f\"Failed to Ingest {os.path.basename(filepath)}\")\n",
    "                failed_ingestion.append(filepath)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred while ingesting {os.path.basename(filepath)}: {e}\")\n",
    "            # traceback.print_exc()\n",
    "            failed_ingestion.append(filepath)\n",
    "\n",
    "print(f\"Total files successfully ingested: {len(successfully_ingested)}\")\n",
    "print(f\"Total files failed ingestion: {len(failed_ingestion)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc6f69-67c8-42cd-9ff4-b378d2495810",
   "metadata": {},
   "source": [
    "#### Import Customer Order Data into PostgreSQL\n",
    "To enable structured querying and analysis of customer interactions, we’ll import a CSV file containing order data into a PostgreSQL database. This script creates a `customer_data` table (if it doesn’t already exist), parses and cleans each row of the CSV, and inserts the data into the table.\n",
    "\n",
    "The code handles timestamp parsing, removes special characters like ® and ™ from product fields, and gracefully manages optional return-related date fields. Once complete, the data will be stored in a structured format and ready for use in later stages of the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db52358-668a-4370-a4ad-aee99fd7b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "\n",
    "# Database connection parameters\n",
    "db_params = {\n",
    "    'dbname': 'customer_data',\n",
    "    'user': 'postgres',\n",
    "    'password': 'password',\n",
    "    'host': IPADDRESS,  # e.g., 'localhost' or the IP address\n",
    "    'port': '5432'   # e.g., '5432'\n",
    "}\n",
    "\n",
    "# CSV file path\n",
    "csv_file_path = './data/orders.csv'\n",
    "\n",
    "# Connect to the database\n",
    "conn = psycopg2.connect(**db_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Create the table if it doesn't exist\n",
    "create_table_query = '''\n",
    "CREATE TABLE IF NOT EXISTS customer_data (\n",
    "    customer_id INTEGER NOT NULL,\n",
    "    order_id INTEGER NOT NULL,\n",
    "    product_name VARCHAR(255) NOT NULL,\n",
    "    product_description VARCHAR NOT NULL,\n",
    "    order_date DATE NOT NULL,\n",
    "    quantity INTEGER NOT NULL,\n",
    "    order_amount DECIMAL(10, 2) NOT NULL,\n",
    "    order_status VARCHAR(50),\n",
    "    return_status VARCHAR(50),\n",
    "    return_start_date DATE,\n",
    "    return_received_date DATE,\n",
    "    return_completed_date DATE,\n",
    "    return_reason VARCHAR(255),\n",
    "    notes TEXT,\n",
    "    PRIMARY KEY (customer_id, order_id)\n",
    ");\n",
    "'''\n",
    "cur.execute(create_table_query)\n",
    "\n",
    "# Open the CSV file and insert data\n",
    "with open(csv_file_path, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # Skip the header row\n",
    "\n",
    "    for row in reader:\n",
    "        # Access columns by index as per the provided structure\n",
    "        order_id = int(row[1])  # OrderID\n",
    "        customer_id = int(row[0])  # CID (Customer ID)\n",
    "\n",
    "        # Correcting the order date to include time\n",
    "        order_date = datetime.strptime(row[4], \"%Y-%m-%dT%H:%M:%S\")  # OrderDate with time\n",
    "\n",
    "        quantity = int(row[5])  # Quantity\n",
    "\n",
    "        # Handle optional date fields with time parsing\n",
    "        return_start_date = datetime.strptime(row[9], \"%Y-%m-%dT%H:%M:%S\") if row[9] else None  # ReturnStartDate\n",
    "        return_received_date = datetime.strptime(row[10],\"%Y-%m-%dT%H:%M:%S\") if row[10] else None  # ReturnReceivedDate\n",
    "        return_completed_date = datetime.strptime(row[11], \"%Y-%m-%dT%H:%M:%S\") if row[11] else None  # ReturnCompletedDate\n",
    "\n",
    "        # Clean product name\n",
    "        product_name = re.sub(r'[®™]', '', row[2])  # ProductName\n",
    "\n",
    "        product_description = re.sub(r'[®™]', '', row[3])\n",
    "        # OrderAmount as float\n",
    "        order_amount = float(row[6].replace(',', ''))\n",
    "\n",
    "        # Insert data into the database\n",
    "        cur.execute(\n",
    "            '''\n",
    "            INSERT INTO customer_data (\n",
    "                customer_id, order_id, product_name, product_description, order_date, quantity, order_amount,\n",
    "                order_status, return_status, return_start_date, return_received_date,\n",
    "                return_completed_date, return_reason, notes\n",
    "            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            ''',\n",
    "            (customer_id, order_id, product_name, product_description, order_date, quantity, order_amount,\n",
    "             row[7],  # OrderStatus\n",
    "             row[8],  # ReturnStatus\n",
    "             return_start_date, return_received_date, return_completed_date,\n",
    "             row[12],  # ReturnReason\n",
    "             row[13])  # Notes\n",
    "        )\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"CSV Data imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b6df3c-2197-4370-ba0b-6a7c9b54a7c0",
   "metadata": {},
   "source": [
    "#### Preview Customer Order Records\n",
    "After importing the CSV data, we can verify the contents of the customer_data table by querying the first few rows. This script connects to the PostgreSQL database, runs a simple SELECT query, and prints out the first five entries along with their column names. It’s a quick way to confirm that the data was ingested and structured correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da511f25-cbf1-4ac1-a621-a0086a6b4e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Database connection parameters\n",
    "db_params = {\n",
    "    'dbname': 'customer_data',\n",
    "    'user': 'postgres',\n",
    "    'password': 'password',\n",
    "    'host': IPADDRESS,  # e.g., 'localhost' or the IP address\n",
    "    'port': '5432'   # e.g., '5432'\n",
    "}\n",
    "\n",
    "# Connect to the database\n",
    "conn = psycopg2.connect(**db_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Query to select the first 5 rows from the customer_data table\n",
    "query = 'SELECT * FROM customer_data LIMIT 5;'\n",
    "\n",
    "# Execute the query\n",
    "cur.execute(query)\n",
    "\n",
    "# Fetch the column headers\n",
    "colnames = [desc[0] for desc in cur.description]\n",
    "\n",
    "# Fetch the first 5 rows\n",
    "rows = cur.fetchall()\n",
    "\n",
    "# Print the headers and the corresponding rows\n",
    "for i, row in enumerate(rows, start=1):\n",
    "    print(f\"\\nRow {i}:\")\n",
    "    for header, value in zip(colnames, row):\n",
    "        print(f\"{header}: {value}\")\n",
    "\n",
    "# Close the connection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f320ccf6-f38a-4522-8e80-f75865692bd2",
   "metadata": {},
   "source": [
    "At this point, we’ve successfully ingested all of our data — including PDF manuals, CSV product records, and structured customer orders — into the system. Everything is now prepared and indexed for use in our RAG pipeline. Next, we’ll shift to testing the deployment using the Blueprint’s built-in UI so you can interact with your virtual assistant and validate that the data retrieval and response generation are working as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eeec5a",
   "metadata": {
    "id": "74eeec5a"
   },
   "source": [
    "## Exposing the Interface for Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f76c683",
   "metadata": {
    "id": "4f76c683"
   },
   "source": [
    "The Blueprint comes equiped with a basic UI for testing the deployment. This interface is served at port 3001. In order to expose the port and try out the interaction, you need to follow the steps below.\n",
    "\n",
    "First, navigate back to the created Launchable instance page and click on the Access menu.\n",
    "\n",
    "\n",
    "![Access Menu](https://github.com/NVIDIA-AI-Blueprints/ai-virtual-assistant/raw/main/docs/imgs/brev-cli-install.png)\n",
    "\n",
    "\n",
    "Scroll down until you find \"Using Tunnels\" section and click on Share a Service button.\n",
    "\n",
    "\n",
    "![Using Tunnels](https://github.com/NVIDIA-AI-Blueprints/ai-virtual-assistant/raw/main/docs/imgs/brev-tunnels.png)\n",
    "\n",
    "\n",
    "Enter the port 3001, as that is where the UI service endpoint is. Confirm with Done. Then click on Edit Access and make the port public:\n",
    "\n",
    "\n",
    "![Share Access](https://github.com/NVIDIA-AI-Blueprints/ai-virtual-assistant/raw/main/docs/imgs/brev-share-access.png)\n",
    "\n",
    "\n",
    "Past this point, by clicking on the link, the UI should appear in your browser and you are free to interact with the assistant and to ask him about the data that was ingested.\n",
    "\n",
    "\n",
    "![AI Virtual Assistant Interface](https://github.com/NVIDIA-AI-Blueprints/ai-virtual-assistant/raw/main/docs/imgs/ai-virtual-assistant-interface.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815b4220",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
